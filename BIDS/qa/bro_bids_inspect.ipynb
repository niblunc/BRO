{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIDS Bro Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIDS directory on renci\n",
    "*make script to automize gathering of subject count, etc...*  \n",
    "**The directory-**  \n",
    "`$ pwd`  \n",
    "`/projects/niblab/bids_projects/Experiments/bro/bids`    \n",
    "**Number of subject directories on RENCI-**    \n",
    "`$ ls -d sub-*/ses-1 | wc -l` \n",
    "`43`    \n",
    "`$ ls -d sub-*/ses-2 | wc -l` `50`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions=['ses-1', 'ses-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume Check  \n",
    "Script to produce volumes file(run on renci): [`bids_quality_check.py`](https://github.com/niblunc/BRO/blob/master/BIDS/qa/bids_quality_check.py)   \n",
    "*add functionality here to produce text file automatically*   \n",
    "See [`CHANGELOG`](https://github.com/niblunc/BRO/blob/master/CHANGELOG.md) for further details on volume check and corrections status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files found not matching expected volume: \\n{ pe: 193, training: 243, resting: 147 }\")\n",
    "  \n",
    "filename='/Users/nikkibytes/Documents/niblunc/bro/bids/qa/bad_volumes.txt'\n",
    "vol_dict = {}\n",
    "with open(filename) as f:\n",
    "    content=f.readlines()\n",
    "    for line in content:\n",
    "        if \"training\" in line:\n",
    "            file=line.split(\"\\t\")[0]\n",
    "            vol=line.split(\"\\t\")[1].strip()\n",
    "        else:\n",
    "            file=line.split(\"\\t\\t\")[0]\n",
    "            vol=line.split(\"\\t\\t\")[1].strip()\n",
    "        temp_tuple=(file,vol)\n",
    "        sub_id = file.split(\":\")[1].split(\"_\")[0]\n",
    "        if sub_id not in vol_dict:\n",
    "            vol_dict[sub_id] = [temp_tuple]\n",
    "        else:\n",
    "            vol_dict[sub_id].append(temp_tuple)\n",
    "\n",
    "for sub in vol_dict:\n",
    "    print(\"\\nID: {}\\n\".format(sub))\n",
    "    for x in vol_dict[sub]:\n",
    "        if \"training\" in x[0]:\n",
    "            print(\"{} \\t{} \".format(x[0], x[1]))\n",
    "        else:\n",
    "            print(\"{} \\t\\t{} \".format(x[0], x[1]))\n",
    "        print(\"********************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing files in subjects by session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this on renci to get output\n",
    "\n",
    "\n",
    "dcms_ses1=[x.split(\"/\")[-1] for x in glob.glob('/projects/niblab/bids_projects/Experiments/bro/bids/sourcedata/DICOM/ses-1/sub-*')]\n",
    "dcms_ses2=[x.split(\"/\")[-1] for x in glob.glob('/projects/niblab/bids_projects/Experiments/bro/bids/sourcedata/DICOM/ses-2/sub-*')]\n",
    "\n",
    "ses1_dcms_ct= len(dcms_ses1)\n",
    "ses2_dcms_ct= len(dcms_ses2)\n",
    "\n",
    "ses1_bids=[x.split(\"/\")[-2] for x in glob.glob('/projects/niblab/bids_projects/Experiments/bro/bids/sub-*/ses-1')]\n",
    "ses2_bids=[x.split(\"/\")[-2] for x in glob.glob('/projects/niblab/bids_projects/Experiments/bro/bids/sub-*/ses-2')]\n",
    "\n",
    "ses1_bids_ct= len(ses1_bids)\n",
    "ses2_bids_ct= len(ses2_bids)\n",
    "\n",
    "\n",
    "ses1_mia_lst=set(ses1_dcms) - set(ses1_bids)\n",
    "ses2_mia_lst=set(ses2_dcms) - set(ses2_bids)\n",
    "\n",
    "if not ses1_mia_lst:\n",
    "    ses1_mia_lst=\"None missing\"\n",
    "if not ses2_mia_lst:\n",
    "    ses2_mia_lst=\"None missing\"\n",
    "    \n",
    "print(\"> Session 1: \\nDICOM subject directory count: \\t{} \\\n",
    "      \\nBIDS subject directory count: \\t{} \\nSubjects missing from BIDS directory: \\t{} \\n \\\n",
    "      \\n\\n> Session 2: \\nDICOM subject directory count: \\t{} \\\n",
    "      \\nBIDS subject directory count: \\t{} \\\n",
    "      \\nSubjects missing from BIDS directory: \\t{} \\n\".format(ses1_dcms_ct,ses1_bids_ct,ses1_mia_lst,ses2_dcms_ct,ses2_bids_ct, ses2_mia_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`> Session 1:`    \n",
    "`DICOM subject directory count: \t50 `        \n",
    "`BIDS subject directory count: \t 43`  \n",
    "`Subjects missing from BIDS directory: \t{'sub-054', 'sub-013', 'sub-017', 'sub-035', 'sub-003', 'sub-004', 'sub-018'} `       \n",
    "\n",
    "`> Session 2:`  \n",
    "`DICOM subject directory count: \t50`       \n",
    "`BIDS subject directory count: \t 50 `  \n",
    "`Subjects missing from BIDS directory: \tNone missing `  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core import display as ICD\n",
    "\n",
    "for sess_id in sessions:\n",
    "    if \"1\" in sess_id:\n",
    "        print(\"\\n> SESSION 1\\n\")\n",
    "    else:\n",
    "        print(\"\\n> SESSION 2\\n\")\n",
    "        \n",
    "    ses_mia=pd.read_csv('bro_{}_missing.csv'.format(sess_id),sep=\"\\t\")\n",
    "    ses_mia.set_index(\"Unnamed: 0\", inplace=True)\n",
    "    ses_mia.index.names=[\"subjects\"]\n",
    "    \n",
    "    ses_pmia=pd.read_csv('bro_{}_partial_missing.csv'.format(sess_id),sep=\"\\t\")\n",
    "    ses_pmia.set_index(\"Unnamed: 0\", inplace=True)\n",
    "    ses_pmia.index.names=[\"subjects\"]\n",
    "    \n",
    "    ses_fd=pd.read_csv('bro_{}_found.csv'.format(sess_id),sep=\"\\t\")\n",
    "    ses_fd.set_index(\"Unnamed: 0\", inplace=True)\n",
    "    ses_fd.index.names=[\"subjects\"]\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"All files found missing: \\t{}\\n\".format(' '.join(ses_mia.index.values)))\n",
    "    print(\"Some files found missing: \\t{}\\n\".format(' '.join(ses_pmia.index.values)))\n",
    "    print(\"All files found: \\t\\t{}\\n\".format(' '.join(ses_fd.index.values)))\n",
    "\n",
    "    print(\"\\nDataframe (Missing files): \")\n",
    "    ICD.display(ses_mia)\n",
    "    print(\"\\nDataframe (Partial files found): \")\n",
    "    ICD.display(ses_pmia)\n",
    "    print(\"\\nDataframe (All files found): \")\n",
    "    ICD.display(ses_fd)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
